<!DOCTYPE html>
<html>
<head>
<title>Kevin Eppacher - Github IO</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=0.9">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="./src/styles.css">
<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico"> <!--http://tools.dynamicdrive.com/favicon/-->

</head>
<body class="w3-light-grey">

<!-- w3-content defines a container for fixed size centered content, 
and is wrapped around the whole page content, except for the footer in this example -->
<div class="w3-content">

<!-- Grid -->
<div class="w3-row">

<!-- Introduction menu -->
<div class="w3-col l4">
  <!-- About Card -->
  <div class="w3-card w3-margin w3-margin-top">
    <a href="./index.html">
      <img src="./img/portrait.jpg" style="width:100%; border-top-left-radius: 20px; border-top-right-radius: 20px;">
    </a>
    <div class="w3-container w3-white" style="border-top-left-radius: 0px; border-top-right-radius: 0px;">
      <a href="./index.html">
        <h4><b>Kevin Eppacher, MSc</b></h4>
      </a>
      
      <p>Robotics Software Engineer specializing in perception-driven autonomy, semantic mapping, and intelligent control. Focused on developing systems that combine vision, optimization, and learning for real-world robotic applications.</p>

      <ul style="list-style-type:none; padding:0px; margin:0px;">
        <hr>

        <li>
          <a href="./cv/KevinEppacherCV.pdf" target="_blank">
            <button class="w3-button w3-padding-16 w3-white w3-block w3-left-align">
              <img style="height:20px; transform:translate(-50%,-2.5px);" src="./img/icons/briefcase.svg"><span><b>CV PDF Download</b></span></b>
            </button>
          </a>
        </li>

        <li>
          <a href="./portfolio.html">
            <button class="w3-button w3-padding-16 w3-white w3-block w3-left-align">
              <img style="height:20px; transform:translate(-50%,-2.5px);" src="./img/icons/square-terminal.svg"><span><b>Portfolio</b></span></b>
            </button>
          </a>
        </li>

        <hr>

        <li>
          <a href="https://github.com/KevinEppacher" target="_blank">
            <button class="w3-button w3-padding-16 w3-white w3-block w3-left-align">
              <img style="height:20px; transform:translate(-50%,-2.5px);" src="./img/icons/github.svg"><span><b>GitHub</b></span></b>
            </button>
          </a>
        </li>

        <li>
          <a href="https://www.linkedin.com/in/kevin-eppacher-4464591a0/" 
            target="_blank" 
            class="w3-button w3-padding-16 w3-white w3-block w3-left-align">
            <img style="height:20px; transform:translate(-40%,-2.5px);" src="./img/icons/linkedin.svg">
            <span><b>LinkedIn</b></span>
          </a>
        </li>

      </ul>
      <p></p>
    </div>
  </div>
  
<!-- END Introduction Menu -->
</div>

<!-- Information Cards -->
<div class="w3-col l8 s12">

  <!-- Content Class -> Holds one Publication -->
  <div class="w3-card-4 w3-margin w3-white" style="padding: 15pt;">
    
    <!-- START GENERATED HTML HERE --><h1>Professional Work</h1>
<p>Last year, I developed a nonlinear Model Predictive Controller (nMPC) based local planner for a Differential Drive Mobile Robot (DDMR) within the ROS Noetic navigation stack.</p>
<p>Unlike conventional reactive planners, an nMPC uses a mathematical model (in this case, a kinematic model) to predict future states and optimize them over a defined horizon. This is done by minimizing a cost function while satisfying both soft and hard constraints, such as obstacle distance, velocity bounds, and input limits.
The local planner was implemented entirely in Python, utilizing the CasADi framework for formulating the nonlinear optimization problem. The IPOPT solver (Interior Point Optimizer) was used to solve the problem at runtime efficiently.</p>
<p>As part of the evaluation, I compared the nMPC planner against established ROS local planners:</p>
<ul>
<li>Dynamic Window Approach (DWA)</li>
<li>Timed Elastic Band (TEB)</li>
</ul>
<p>The nMPC planner receives a global reference trajectory (e.g., from an RRT-based global planner) and computes optimized control inputs at higher frequency to achieve smooth and safe local obstacle avoidance, even in dynamic and narrow environments.</p>
<ul>
<li>The system was simulated in Gazebo with a TurtleBot platform and fully integrated with ROS Noetic.</li>
<li>üê≥ A GPU-enabled Docker container is provided for fast and reproducible setup.</li>
<li>üìÅ The GitHub repository includes the full source code, parameter tuning, scientific paper, and presentation slides.</li>
</ul>
<p>üîó https://lnkd.in/dgpq7y2Y</p>
<p>Hashtag#Robotics Hashtag#MPC Hashtag#nMPC Hashtag#CasADi Hashtag#IPOPT Hashtag#PathPlanning Hashtag#ROS Hashtag#ROSNoetic Hashtag#</p>
<p>/home/kevin/Documents/Allgemein/KevinEppacher.github.io/videos/nMPC.mp4</p>
<hr />
<p>Collaborative Project with AIRSKIN‚Äì Automated Sensitivity Measurement System ü§ñüìè
Last year, Moritz D√∂nges and I had the opportunity to design an automated measurement system in collaboration with AIRSKIN at the University of Applied Sciences Technikum Wien.
üéØ The goal was to measure the force required to trigger an AIRSKIN pad and the displacement at that moment. This allowed us to calculate the spring constant, thereby defining the sensitivity at each measurement point. This system plays an important role in identifying weak points and supporting further development of AIRSKIN pads.
üõ†Ô∏è The system was built using ROS Noetic and Docker. We developed a custom C++ ImGui HMI that allows the UR10 robot to be switched between Freedrive Mode for teaching points and External Control Mode for automated measurements. Thanks to the ROS UR hardware interface, the robot can seamlessly switch between modes, start/stop programs, and communicate with the FT sensor via UR ROS bridge (TCP/IP protocol).
üìç Once all points are taught, a MoveIt MoveGroup program automatically moves the robot to each point, measuring and visualizing the applied force in RViz. A 3D camera visualizes a point cloud, allowing for intuitive analysis of the AIRSKIN pad and the corresponding force vectors.
üöß Future plans include integrating RGB-D-based obstacle avoidance to dynamically navigate between measurement points.
The entire system was also implemented in Gazebo for simulation purposes.
üñ•Ô∏è The project is available here:
https://lnkd.in/dYwSsFtR</p>
<p>Hashtag#Robotics Hashtag#ROS Hashtag#AIRSKIN Hashtag#UR10 Hashtag#Automation Hashtag#ForceMeasurement Hashtag#HumanRob</p>
<p>Paths:
videos/sensibility_measurements.mp4</p>
<hr />
<p>üöÄ Monte Carlo Localization (Particle Filter) for Mobile Robots ü§ñüåü
Last year, during my second master's semester, I had the opportunity to work on a project where I implemented a Monte Carlo Localization (MCL) algorithm, also known as a particle filter, for the localization of Differential Drive Mobile Robots (DDMR).</p>
<p>The core idea behind the particle filter is simple yet powerful: It utilizes a predefined map, a motion model for prediction, and weights each particle based on raycasting within a probabilistic measurement model. I developed a ROS Noetic C++ implementation, simulating a Turtlebot navigating through a small apartment environment within Gazebo.</p>
<p>Key Highlights of My Approach:</p>
<ul>
<li>Efficient Particle Usage: Achieving reliable localization with only 100 particles, compared to the typical 500 to 3000 particles used by ROS Adaptive Monte Carlo Localization (AMCL) for a small apartment environment.</li>
<li>Innovative Resampling Strategy: Introducing randomness by generating 80% of the particles every time. This approach greatly improves the algorithm‚Äôs ability to quickly determine the initial pose and recover from localization loss.</li>
</ul>
<p>Check out the full details and code here: https://lnkd.in/dE9Z88Zq</p>
<p>I'd love to hear your thoughts and feedback! üöÄü§ñ
Hashtag#Robotics Hashtag#Localization Hashtag#MonteCarlo Hashtag#AMCL Hashtag#MachineLearning Hashtag#ROS Hashtag#C++ Hashtag#Gazebo Hashtag#Simulation</p>
<p>Paths:
videos/mcl.gif</p>
<hr />
<p>Bachelor Thesis:</p>
<p>The recent rapid growth in popularity of UAVs (drones) has led to a variety of new applications and opportunities. At the same time, however, serious safety concerns and potential hazards have emerged, affecting both airports and individuals.</p>
<p>My bachelor thesis aims to address this issue. At the Automation and Control Institute (TU), I was privileged to develop a control system for tracking drones at short distances and high speeds using a pan-tilt (PT) camera.</p>
<p>I developed a cascaded position and velocity controller to control the pan and tilt axis, which are driven by a permanent magnet synchronous motor (PMSM) with a field oriented control (FOC) algorithm. In addition, the drone's trajectory is smoothed, interpolated, and predicted using the Kalman filter (sensor fusion) in case the drone disappears from the field of view or becomes undetectable. The methods were simulated in the Robot Operating System (ROS) and using OpenCV.</p>
<p>In a reproducible experiment, a laser beam with a defined trajectory was specified for the PT camera to track. During the tracking, the laser point detection algorithm is briefly disabled to further estimate the motion of the respective axes.</p>
<p>The results showed that by using the cascaded position and velocity controller, 1 rad/s can be achieved and therefore the drones can track at a distance of 30 m with a velocity of 30 m/s.</p>
<p>Hashtag#UAV Hashtag#DroneTechnology Hashtag#ControlSystems Hashtag#Automation Hashtag#Research Hashtag#Thesis Hashtag#Innovation</p>
<p>Paths:
videos/OptoFence_Video_3.mp4</p>
<h1>Personal Projects</h1>
<hr />
<p>In this project, a 6-DOF robotic arm has been designed and built which is driven by stepper motors and various gears such as 3D printed harmonic drives and timing belts.</p>
<p>The robot arm is controlled via ROS (Robot Operating System) using the MoveIt package. The MoveIt package visualizes and controls the robot arm on RViz, and in the background, it calculates the collision matrix so that the robot arm cannot collide with itself.</p>
<p>Through the visualization of RViz, the robot arm is simulated in the program and this simulation is transferred to the real robot .ü¶æ</p>
<p>Next step is, to make it üëÄ</p>
<p>Hashtag#Robot Hashtag#ROS Hashtag#3Dprinted Hashtag#PickAndPlace Hashtag#stepper Hashtag#MoveIt Hashtag#gripper Hashtag#innovation Hashtag#fromscr</p>
<p>Paths:
 img/6_DOFRA_Rendered_1.png
 img/6_DOFRA_Rendered_2.png
 videos/6dofra.mp4</p>
<!-- END GENERATED HTML HERE -->

  </div>

<!-- END Information Cards -->
</div>

<!-- END GRID -->
</div>

<!-- END w3-content -->
</div>

<!-- Footer -->
<footer>
  <p style="margin-top:3cm;"><b>2024 Kevin Eppacher.</b>
  Powered by <u><a href="https://www.w3schools.com/w3css/default.asp" target="_blank">w3.css</a></u>.
  Icons by <u><a href="https://www.flaticon.com/icon-fonts-most-downloaded" target="_blank">flaticon.com</a></u>.
  Styling modified from <u><a href="https://github.com/KrauseFx/markdown-to-html-github-style/tree/master" target="_blank">markdown-to-html-github-style.</a></u>
  <p>This website is licensed under a <u><a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License.</a></u>
  Website source code can be borrowed, but link back to the template in your footer.</p>
</footer>

</body>
</html>
